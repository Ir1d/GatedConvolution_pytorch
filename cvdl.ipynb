{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import FileLink\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from models.gatedconv import InpaintGCNet, InpaintDirciminator\n",
    "from models.unet_fastai import InpaintSANet, InpaintSADirciminator\n",
    "from models.loss import SNDisLoss, SNGenLoss, ReconLoss, NewLoss\n",
    "\n",
    "from util.logger import TensorBoardLogger\n",
    "from util.config import Config\n",
    "from data.fastai_dataset import InpaintDataset\n",
    "from util.evaluation import AverageMeter\n",
    "from evaluation import metrics\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = Config('config/inpaint_places2_sagan.yml')\n",
    "logger = logging.getLogger(__name__)\n",
    "time_stamp = time.strftime('%Y%m%d%H%M', time.localtime(time.time()))\n",
    "log_dir = 'model_logs/{}_{}'.format(time_stamp, config.LOG_DIR)\n",
    "result_dir = 'result_logs/{}_{}'.format(time_stamp, config.LOG_DIR)\n",
    "tensorboardlogger = TensorBoardLogger(log_dir)\n",
    "cuda0 = torch.device('cuda:{}'.format(config.GPU_ID))\n",
    "cpu0 = torch.device('cpu')\n",
    "\n",
    "def logger_init():\n",
    "    \"\"\"\n",
    "    Initialize the logger to some file.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logfile = 'logs/{}_{}.log'.format(time_stamp, config.LOG_DIR)\n",
    "    fh = logging.FileHandler(logfile, mode='w')\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mine': '/home/xudejia/inpainting/data/train_mask_list.txt'}\n",
      "{'val': '/home/xudejia/inpainting/data/val_mask_list.txt'}\n"
     ]
    }
   ],
   "source": [
    "    logger_init()\n",
    "    dataset_type = config.DATASET\n",
    "    batch_size = config.BATCH_SIZE\n",
    "train_dataset = InpaintDataset(config.DATA_FLIST[dataset_type][0],\\\n",
    "                                      {mask_type:config.DATA_FLIST[config.MASKDATASET][mask_type][0] for mask_type in config.MASK_TYPES}, \\\n",
    "                                      resize_shape=tuple(config.IMG_SHAPES), random_bbox_shape=config.RANDOM_BBOX_SHAPE, \\\n",
    "                                      random_bbox_margin=config.RANDOM_BBOX_MARGIN,\n",
    "                                      random_ff_setting=config.RANDOM_FF_SETTING)\n",
    "val_dataset = InpaintDataset(config.DATA_FLIST[dataset_type][1],\\\n",
    "                                    {mask_type:config.DATA_FLIST[config.MASKDATASET][mask_type][1] for mask_type in ('val',)}, \\\n",
    "                                    resize_shape=tuple(config.IMG_SHAPES), random_bbox_shape=config.RANDOM_BBOX_SHAPE, \\\n",
    "                                    random_bbox_margin=config.RANDOM_BBOX_MARGIN,\n",
    "                                    random_ff_setting=config.RANDOM_FF_SETTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Finish the dataset initialization.\n"
     ]
    }
   ],
   "source": [
    "db = DataBunch.create(train_ds=train_dataset, valid_ds=val_dataset, bs=8, val_bs=8,num_workers=16, pin_memory=True)\n",
    "logger.info(\"Finish the dataset initialization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncnt = 0\\nfor w in db.train_ds:\\n    cnt = cnt + 1\\n    print('?', len(w))\\n    print(len(w[0]))\\n    for x in w[0]:\\n        print(x)\\n    if (cnt > 2):\\n        \\n        break\\nprint(cnt)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnt = 0\n",
    "for w in db.train_ds:\n",
    "    cnt = cnt + 1\n",
    "    print('?', len(w))\n",
    "    print(len(w[0]))\n",
    "    for x in w[0]:\n",
    "        print(x)\n",
    "    if (cnt > 2):\n",
    "        \n",
    "        break\n",
    "print(cnt)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Define the Network Structure and Losses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif config.MODEL_RESTORE != \\'\\':\\n        whole_model_path = \\'model_logs/{}\\'.format( config.MODEL_RESTORE)\\n        nets = torch.load(whole_model_path)\\n        netG_state_dict, netD_state_dict = nets[\\'netG_state_dict\\'], nets[\\'netD_state_dict\\']\\n        netG.load_state_dict(netG_state_dict)\\n        netD.load_state_dict(netD_state_dict)\\n        logger.info(\"Loading pretrained models from {} ...\".format(config.MODEL_RESTORE))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Define the Network Structure and Losses\")\n",
    "netG = InpaintSANet()\n",
    "# netD = InpaintSADirciminator()\n",
    "\"\"\"\n",
    "if config.MODEL_RESTORE != '':\n",
    "        whole_model_path = 'model_logs/{}'.format( config.MODEL_RESTORE)\n",
    "        nets = torch.load(whole_model_path)\n",
    "        netG_state_dict, netD_state_dict = nets['netG_state_dict'], nets['netD_state_dict']\n",
    "        netG.load_state_dict(netG_state_dict)\n",
    "        netD.load_state_dict(netD_state_dict)\n",
    "        logger.info(\"Loading pretrained models from {} ...\".format(config.MODEL_RESTORE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLoss = ReconLoss(*(config.L1_LOSS_ALPHA))\n",
    "GLoss = SNGenLoss(config.GAN_LOSS_ALPHA)\n",
    "DLoss = SNDisLoss()\n",
    "NLoss = NewLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SaveModelCallback(learn, every='improvement', monitor='accuracy', name='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyLoss(out, img, masks):\n",
    "    \"\"\"\n",
    "    print(len(out))\n",
    "    print(len(target))\n",
    "    print(len(ww))\n",
    "    for x in out:\n",
    "        print(x.shape)\n",
    "    for x in target:\n",
    "        print(x.shape)\n",
    "    for x in ww:\n",
    "        print(x.shape)\n",
    "    \"\"\"\n",
    "    coarse_imgs, refined, mixed = out\n",
    "    # img, masks = target\n",
    "    complete_imgs = mixed\n",
    "    r_loss = RLoss(img, coarse_imgs, mixed, masks)\n",
    "    n_loss = NLoss(coarse_imgs, refined, mixed, img)\n",
    "    return r_loss + n_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2photo(imgs):\n",
    "    # torch.Size([3, 256, 256])\n",
    "    # return ((imgs+1)*127.5).detach().cpu().numpy()\n",
    "    return ((imgs+1)/2).detach().cpu()\n",
    "    # return ((imgs+1)*127.5).transpose(0, 1).transpose(1, 2).detach().cpu().numpy().astype(np.uint8)\n",
    "    # return ((imgs+1)*127.5).transpose(1,2).transpose(2,3).detach().cpu().numpy()\n",
    "class TensorboardLogger(Callback):\n",
    "    \"\"\"\n",
    "    A general Purpose Logger for TensorboardX\n",
    "    Also save a .txt file for the important parts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner, log_name, cfgtxt, del_existing=False, histogram_freq=100):\n",
    "        \"\"\"\n",
    "        Learner is the ConvLearner\n",
    "        log_name: name of the log directory to be formed. Will be input\n",
    "        for each run\n",
    "        cfgtxt: HyperParams\n",
    "        del_existing: To run the experiment from scratch and remove previous logs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.learn = learner\n",
    "        self.model = learner.model\n",
    "        self.md = learner.data\n",
    "\n",
    "        self.metrics_names = [\"validation_loss\"]\n",
    "        self.metrics_names += [m.__name__ for m in learner.metrics]\n",
    "\n",
    "        self.best_met = 0\n",
    "\n",
    "        self.histogram_freq = histogram_freq\n",
    "        self.cfgtxt = cfgtxt\n",
    "\n",
    "        path = Path(self.md.path) / \"model_logs\"\n",
    "        self.log_name = log_name\n",
    "        self.log_dir = path / log_name\n",
    "\n",
    "        self.init_logs(self.log_dir, del_existing)\n",
    "        self.init_tb_writer()\n",
    "        self.init_txt_writer(path, log_name)\n",
    "\n",
    "    def init_logs(self, log_dir, del_existing):\n",
    "        if log_dir.exists():\n",
    "            if del_existing:\n",
    "                print(f'removing existing log with same name {log_dir.stem}')\n",
    "                shutil.rmtree(self.log_dir)\n",
    "\n",
    "    def init_tb_writer(self):\n",
    "        self.writer = SummaryWriter(\n",
    "            comment='main_mdl', log_dir=str(self.log_dir))\n",
    "        self.writer.add_text('HyperParams', self.cfgtxt)\n",
    "\n",
    "    def init_txt_writer(self, path, log_name):\n",
    "        self.fw_ = path / f'{log_name}.txt'\n",
    "        self.str_form = '{} \\t {} \\t '\n",
    "        for m in self.metrics_names:\n",
    "            self.str_form += '{} \\t '\n",
    "        self.str_form += '\\n'\n",
    "        self.out_str = self.str_form.format(\n",
    "            'epoch', 'trn_loss', *self.metrics_names)\n",
    "\n",
    "        with open(self.fw_, 'w') as f:\n",
    "            f.write(self.cfgtxt)\n",
    "            f.write('\\n')\n",
    "            f.write(self.out_str)\n",
    "\n",
    "    def on_batch_end(self, **kwargs):\n",
    "        self.trn_loss = kwargs['last_loss']\n",
    "        num_batch = kwargs['num_batch']\n",
    "        self.writer.add_scalar(\n",
    "            'trn_loss_batch', self.trn_loss, num_batch)\n",
    "        last_output = kwargs['last_output']\n",
    "        last_target = kwargs['last_target']\n",
    "        epoch = kwargs['epoch']\n",
    "        iteration = kwargs['iteration']\n",
    "        if iteration % 5 == 0:\n",
    "            \"\"\"\n",
    "            print(len(last_target[0]))\n",
    "            for x in last_target[0]:\n",
    "                print(x.shape)\n",
    "            \"\"\"\n",
    "            imgs, masks = last_target[0][0].detach(), last_target[1][0].detach()\n",
    "            coarse_imgs, refined, complete_imgs = last_output[0][0].detach(), last_output[1][0].detach(), last_output[2][0].detach()\n",
    "            # torch.Size([3, 256, 256])\n",
    "            img = img2photo(torch.cat([imgs * (1 - masks) + masks, refined, imgs * masks, complete_imgs, imgs], dim=2))\n",
    "            self.writer.add_image('train/whole_imgs%d'%epoch, img, iteration)\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        metrics = kwargs['last_metrics']\n",
    "        epoch = kwargs['epoch']\n",
    "        trn_loss = kwargs['smooth_loss']\n",
    "        self.writer.add_scalar('trn_loss', trn_loss, epoch)\n",
    "\n",
    "        for val, name in zip(metrics, self.metrics_names):\n",
    "            self.writer.add_scalar(name, val, epoch)\n",
    "\n",
    "        self.file_write(self.str_form.format(epoch,\n",
    "                                             self.trn_loss, *metrics))\n",
    "\n",
    "        m = metrics[1]\n",
    "        if m > self.best_met:\n",
    "            self.best_met = m\n",
    "            self.learn.save(self.log_name)\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        self.writer.add_text('Total Epochs', str(kwargs['epoch']))\n",
    "        self.writer.close()\n",
    "        self.file_write(f'Epochs done, {kwargs[\"epoch\"]}')\n",
    "\n",
    "    def file_write(self, outstr):\n",
    "        with open(self.fw_, 'a') as f:\n",
    "            f.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNR(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self):\n",
    "        # If it's a partial, use func.func\n",
    "        # name = getattr(func,'func',func).__name__\n",
    "        self.name = 'PSNR'\n",
    "        self.func = metrics['ppsnr']\n",
    "        # self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            ww = kwargs['last_output']\n",
    "            aa = kwargs['last_target']\n",
    "            last_output = ww[-1]\n",
    "            last_target = aa[0]\n",
    "            \"Update metric computation with `last_output` and `last_target`.\"\n",
    "            if not is_listy(last_target): last_target=[last_target]\n",
    "            self.count += last_target[0].size(0)\n",
    "            \"\"\"\n",
    "            print(len(last_output))\n",
    "            for x in last_output:\n",
    "                print(x.shape)\n",
    "            \"\"\"\n",
    "            # val = self.func(last_output, *last_target)\n",
    "            val = self.func(*last_target, last_output)\n",
    "            self.val += last_target[0].size(0) * val\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)\n",
    "class SSIM(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self):\n",
    "        # If it's a partial, use func.func\n",
    "        # name = getattr(func,'func',func).__name__\n",
    "        self.name = 'SSIM'\n",
    "        self.func = metrics['sssim']\n",
    "        # self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            ww = kwargs['last_output']\n",
    "            aa = kwargs['last_target']\n",
    "            last_output = ww[-1]\n",
    "            last_target = aa[0]\n",
    "            # last_output = last_output[0]\n",
    "            \"Update metric computation with `last_output` and `last_target`.\"\n",
    "            if not is_listy(last_target): last_target=[last_target]\n",
    "            self.count += last_target[0].size(0)\n",
    "            # val = self.func(last_output, *last_target)\n",
    "            val = self.func(*last_target, last_output)\n",
    "            self.val += last_target[0].size(0) * val\n",
    "        # self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)\n",
    "psnr = PSNR()\n",
    "ssim = SSIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, decay = config.LEARNING_RATE, config.WEIGHT_DECAY\n",
    "learn = Learner(db, netG, loss_func=MyLoss, metrics=[psnr, ssim], callback_fns=[partial(EarlyStoppingCallback, monitor='psnr', min_delta=0.1, patience=3)], model_dir='./weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='748' class='' max='1000', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      74.80% [748/1000 02:58<01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xudejia/anaconda2/envs/py3.6/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(50, lr=1e-3, callback_fns=[SaveModelCallback(learn, every='improvement', monitor='psnr', name='best'), TensorboardLogger(learn, \"fastai-1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "# learn.fit_one_cycle(1, max_lr=lr, callbacks=[SaveModelCallback(learn, every='improvement', monitor='psnr', name='best'), TensorboardLogger(learn, \"fastai-1\", cfgtxt=str(lr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
