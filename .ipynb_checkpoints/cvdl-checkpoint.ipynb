{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import FileLink\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from models.gatedconv import InpaintGCNet, InpaintDirciminator\n",
    "from models.unet_fastai import InpaintSANet, InpaintSADirciminator\n",
    "from models.loss import SNDisLoss, SNGenLoss, ReconLoss, NewLoss\n",
    "\n",
    "from util.logger import TensorBoardLogger\n",
    "from util.config import Config\n",
    "from data.fastai_dataset import InpaintDataset\n",
    "from util.evaluation import AverageMeter\n",
    "from evaluation import metrics\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = Config('config/inpaint_places2_sagan.yml')\n",
    "logger = logging.getLogger(__name__)\n",
    "time_stamp = time.strftime('%Y%m%d%H%M', time.localtime(time.time()))\n",
    "log_dir = 'model_logs/{}_{}'.format(time_stamp, config.LOG_DIR)\n",
    "result_dir = 'result_logs/{}_{}'.format(time_stamp, config.LOG_DIR)\n",
    "tensorboardlogger = TensorBoardLogger(log_dir)\n",
    "cuda0 = torch.device('cuda:{}'.format(config.GPU_ID))\n",
    "cpu0 = torch.device('cpu')\n",
    "\n",
    "def logger_init():\n",
    "    \"\"\"\n",
    "    Initialize the logger to some file.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logfile = 'logs/{}_{}.log'.format(time_stamp, config.LOG_DIR)\n",
    "    fh = logging.FileHandler(logfile, mode='w')\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mine': '/home/xudejia/inpainting/data/train_mask_list.txt'}\n",
      "{'val': '/home/xudejia/inpainting/data/val_mask_list.txt'}\n"
     ]
    }
   ],
   "source": [
    "    logger_init()\n",
    "    dataset_type = config.DATASET\n",
    "    batch_size = config.BATCH_SIZE\n",
    "train_dataset = InpaintDataset(config.DATA_FLIST[dataset_type][0],\\\n",
    "                                      {mask_type:config.DATA_FLIST[config.MASKDATASET][mask_type][0] for mask_type in config.MASK_TYPES}, \\\n",
    "                                      resize_shape=tuple(config.IMG_SHAPES), random_bbox_shape=config.RANDOM_BBOX_SHAPE, \\\n",
    "                                      random_bbox_margin=config.RANDOM_BBOX_MARGIN,\n",
    "                                      random_ff_setting=config.RANDOM_FF_SETTING)\n",
    "val_dataset = InpaintDataset(config.DATA_FLIST[dataset_type][1],\\\n",
    "                                    {mask_type:config.DATA_FLIST[config.MASKDATASET][mask_type][1] for mask_type in ('val',)}, \\\n",
    "                                    resize_shape=tuple(config.IMG_SHAPES), random_bbox_shape=config.RANDOM_BBOX_SHAPE, \\\n",
    "                                    random_bbox_margin=config.RANDOM_BBOX_MARGIN,\n",
    "                                    random_ff_setting=config.RANDOM_FF_SETTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Finish the dataset initialization.\n"
     ]
    }
   ],
   "source": [
    "db = DataBunch.create(train_ds=train_dataset, valid_ds=val_dataset, bs=8, val_bs=8,num_workers=16, pin_memory=True)\n",
    "logger.info(\"Finish the dataset initialization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncnt = 0\\nfor w in db.train_ds:\\n    cnt = cnt + 1\\n    print('?', len(w))\\n    print(len(w[0]))\\n    for x in w[0]:\\n        print(x)\\n    if (cnt > 2):\\n        \\n        break\\nprint(cnt)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnt = 0\n",
    "for w in db.train_ds:\n",
    "    cnt = cnt + 1\n",
    "    print('?', len(w))\n",
    "    print(len(w[0]))\n",
    "    for x in w[0]:\n",
    "        print(x)\n",
    "    if (cnt > 2):\n",
    "        \n",
    "        break\n",
    "print(cnt)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Define the Network Structure and Losses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif config.MODEL_RESTORE != \\'\\':\\n        whole_model_path = \\'model_logs/{}\\'.format( config.MODEL_RESTORE)\\n        nets = torch.load(whole_model_path)\\n        netG_state_dict, netD_state_dict = nets[\\'netG_state_dict\\'], nets[\\'netD_state_dict\\']\\n        netG.load_state_dict(netG_state_dict)\\n        netD.load_state_dict(netD_state_dict)\\n        logger.info(\"Loading pretrained models from {} ...\".format(config.MODEL_RESTORE))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Define the Network Structure and Losses\")\n",
    "netG = InpaintSANet()\n",
    "# netD = InpaintSADirciminator()\n",
    "\"\"\"\n",
    "if config.MODEL_RESTORE != '':\n",
    "        whole_model_path = 'model_logs/{}'.format( config.MODEL_RESTORE)\n",
    "        nets = torch.load(whole_model_path)\n",
    "        netG_state_dict, netD_state_dict = nets['netG_state_dict'], nets['netD_state_dict']\n",
    "        netG.load_state_dict(netG_state_dict)\n",
    "        netD.load_state_dict(netD_state_dict)\n",
    "        logger.info(\"Loading pretrained models from {} ...\".format(config.MODEL_RESTORE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLoss = ReconLoss(*(config.L1_LOSS_ALPHA))\n",
    "GLoss = SNGenLoss(config.GAN_LOSS_ALPHA)\n",
    "DLoss = SNDisLoss()\n",
    "NLoss = NewLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SaveModelCallback(learn, every='improvement', monitor='accuracy', name='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyLoss(out, img, masks):\n",
    "    \"\"\"\n",
    "    print(len(out))\n",
    "    print(len(target))\n",
    "    print(len(ww))\n",
    "    for x in out:\n",
    "        print(x.shape)\n",
    "    for x in target:\n",
    "        print(x.shape)\n",
    "    for x in ww:\n",
    "        print(x.shape)\n",
    "    \"\"\"\n",
    "    coarse_imgs, refined, mixed = out\n",
    "    # img, masks = target\n",
    "    complete_imgs = mixed\n",
    "    r_loss = RLoss(img, coarse_imgs, mixed, masks)\n",
    "    n_loss = NLoss(coarse_imgs, refined, mixed, img)\n",
    "    return r_loss + n_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2photo(imgs):\n",
    "    # torch.Size([3, 256, 256])\n",
    "    # return ((imgs+1)*127.5).detach().cpu().numpy()\n",
    "    return ((imgs+1)/2).detach().cpu()\n",
    "    # return ((imgs+1)*127.5).transpose(0, 1).transpose(1, 2).detach().cpu().numpy().astype(np.uint8)\n",
    "    # return ((imgs+1)*127.5).transpose(1,2).transpose(2,3).detach().cpu().numpy()\n",
    "class TensorboardLogger(Callback):\n",
    "    \"\"\"\n",
    "    A general Purpose Logger for TensorboardX\n",
    "    Also save a .txt file for the important parts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner, log_name, cfgtxt, del_existing=False, histogram_freq=100):\n",
    "        \"\"\"\n",
    "        Learner is the ConvLearner\n",
    "        log_name: name of the log directory to be formed. Will be input\n",
    "        for each run\n",
    "        cfgtxt: HyperParams\n",
    "        del_existing: To run the experiment from scratch and remove previous logs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.learn = learner\n",
    "        self.model = learner.model\n",
    "        self.md = learner.data\n",
    "\n",
    "        self.metrics_names = [\"validation_loss\"]\n",
    "        self.metrics_names += [m.__name__ for m in learner.metrics]\n",
    "\n",
    "        self.best_met = 0\n",
    "\n",
    "        self.histogram_freq = histogram_freq\n",
    "        self.cfgtxt = cfgtxt\n",
    "\n",
    "        path = Path(self.md.path) / \"model_logs\"\n",
    "        self.log_name = log_name\n",
    "        self.log_dir = path / log_name\n",
    "\n",
    "        self.init_logs(self.log_dir, del_existing)\n",
    "        self.init_tb_writer()\n",
    "        self.init_txt_writer(path, log_name)\n",
    "\n",
    "    def init_logs(self, log_dir, del_existing):\n",
    "        if log_dir.exists():\n",
    "            if del_existing:\n",
    "                print(f'removing existing log with same name {log_dir.stem}')\n",
    "                shutil.rmtree(self.log_dir)\n",
    "\n",
    "    def init_tb_writer(self):\n",
    "        self.writer = SummaryWriter(\n",
    "            comment='main_mdl', log_dir=str(self.log_dir))\n",
    "        self.writer.add_text('HyperParams', self.cfgtxt)\n",
    "\n",
    "    def init_txt_writer(self, path, log_name):\n",
    "        self.fw_ = path / f'{log_name}.txt'\n",
    "        self.str_form = '{} \\t {} \\t '\n",
    "        for m in self.metrics_names:\n",
    "            self.str_form += '{} \\t '\n",
    "        self.str_form += '\\n'\n",
    "        self.out_str = self.str_form.format(\n",
    "            'epoch', 'trn_loss', *self.metrics_names)\n",
    "\n",
    "        with open(self.fw_, 'w') as f:\n",
    "            f.write(self.cfgtxt)\n",
    "            f.write('\\n')\n",
    "            f.write(self.out_str)\n",
    "\n",
    "    def on_batch_end(self, **kwargs):\n",
    "        self.trn_loss = kwargs['last_loss']\n",
    "        num_batch = kwargs['num_batch']\n",
    "        self.writer.add_scalar(\n",
    "            'trn_loss_batch', self.trn_loss, num_batch)\n",
    "        last_output = kwargs['last_output']\n",
    "        last_target = kwargs['last_target']\n",
    "        epoch = kwargs['epoch']\n",
    "        iteration = kwargs['iteration']\n",
    "        if iteration % 5 == 0:\n",
    "            \"\"\"\n",
    "            print(len(last_target[0]))\n",
    "            for x in last_target[0]:\n",
    "                print(x.shape)\n",
    "            \"\"\"\n",
    "            imgs, masks = last_target[0][0].detach(), last_target[1][0].detach()\n",
    "            coarse_imgs, refined, complete_imgs = last_output[0][0].detach(), last_output[1][0].detach(), last_output[2][0].detach()\n",
    "            # torch.Size([3, 256, 256])\n",
    "            img = img2photo(torch.cat([imgs * (1 - masks) + masks, refined, imgs * masks, complete_imgs, imgs], dim=2))\n",
    "            self.writer.add_image('train/whole_imgs%d'%epoch, img, iteration)\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        metrics = kwargs['last_metrics']\n",
    "        epoch = kwargs['epoch']\n",
    "        trn_loss = kwargs['smooth_loss']\n",
    "        self.writer.add_scalar('trn_loss', trn_loss, epoch)\n",
    "\n",
    "        for val, name in zip(metrics, self.metrics_names):\n",
    "            self.writer.add_scalar(name, val, epoch)\n",
    "\n",
    "        self.file_write(self.str_form.format(epoch,\n",
    "                                             self.trn_loss, *metrics))\n",
    "\n",
    "        m = metrics[1]\n",
    "        if m > self.best_met:\n",
    "            self.best_met = m\n",
    "            self.learn.save(self.log_name)\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        self.writer.add_text('Total Epochs', str(kwargs['epoch']))\n",
    "        self.writer.close()\n",
    "        self.file_write(f'Epochs done, {kwargs[\"epoch\"]}')\n",
    "\n",
    "    def file_write(self, outstr):\n",
    "        with open(self.fw_, 'a') as f:\n",
    "            f.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNR(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self):\n",
    "        # If it's a partial, use func.func\n",
    "        # name = getattr(func,'func',func).__name__\n",
    "        self.name = 'PSNR'\n",
    "        self.func = metrics['ppsnr']\n",
    "        # self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output[-1]\n",
    "        last_target = last_target[0]\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "        if not is_listy(last_target): last_target=[last_target]\n",
    "        self.count += last_target[0].size(0)\n",
    "        \"\"\"\n",
    "        print(len(last_output))\n",
    "        for x in last_output:\n",
    "            print(x.shape)\n",
    "        \"\"\"\n",
    "        # val = self.func(last_output, *last_target)\n",
    "        val = self.func(*last_target, last_output)\n",
    "        self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)\n",
    "class SSIM(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self):\n",
    "        # If it's a partial, use func.func\n",
    "        # name = getattr(func,'func',func).__name__\n",
    "        self.name = 'SSIM'\n",
    "        self.func = metrics['sssim']\n",
    "        # self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output[-1]\n",
    "        last_target = last_target[0]\n",
    "        # last_output = last_output[0]\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "        if not is_listy(last_target): last_target=[last_target]\n",
    "        self.count += last_target[0].size(0)\n",
    "        # val = self.func(last_output, *last_target)\n",
    "        val = self.func(*last_target, last_output)\n",
    "        self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)\n",
    "psnr = PSNR()\n",
    "ssim = SSIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, decay = config.LEARNING_RATE, config.WEIGHT_DECAY\n",
    "learn = Learner(db, netG, loss_func=MyLoss, metrics=[psnr, ssim], callback_fns=[partial(EarlyStoppingCallback, monitor='psnr', min_delta=0.1, patience=3)], model_dir='./weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"int\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-631604a2e07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, dl, callbacks, metrics)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcb_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_batch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;34m\"Handle end of processing one batch with `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;34m\"Call through to all of the `CallbakHandler` functions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m_call_and_update\u001b[0;34m(self, cb, cb_name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;34m\"Call `cb_name` on `cb` and update the inner state.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-5f330b8426b2>\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, last_output, last_target, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# val = self.func(last_output, *last_target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd/xudejia/inpainting/GatedConvolution_pytorch/evaluation/__init__.py\u001b[0m in \u001b[0;36mppsnr\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mppsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ssd/xudejia/inpainting/GatedConvolution_pytorch/evaluation/__init__.py\u001b[0m in \u001b[0;36mff\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mppsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
     ]
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(50, lr=1e-3, callback_fns=[SaveModelCallback(learn, every='improvement', monitor='psnr', name='best'), TensorboardLogger(learn, \"fastai-1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "# learn.fit_one_cycle(1, max_lr=lr, callbacks=[SaveModelCallback(learn, every='improvement', monitor='psnr', name='best'), TensorboardLogger(learn, \"fastai-1\", cfgtxt=str(lr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
